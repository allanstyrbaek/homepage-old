<html lang="en">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.11: http://docutils.sourceforge.net/" />
<title></title>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,500'
      rel='stylesheet' type='text/css'>
<link href="bootstrap/css/bootstrap.css" rel="stylesheet"/>
<link href="bootstrap/css/bootstrap-responsive.css" rel="stylesheet"/>
<link href="../bootstrap/css/bootstrap.css" rel="stylesheet"/>
<link href="../bootstrap/css/bootstrap-responsive.css" rel="stylesheet"/>
<link rel="stylesheet" href="../style.css" type="text/css" />
</head>
<body>
<div class="header">
<p>header</p>

<hr class="header"/>
</div>
<div class="container-fluid">


<div class="offset1 span2 sidebar">
<p class="first sidebar-title">Nicolas P. Rougier</p>
<p><a class="reference external" href="mailto:Nicolas&#46;Rougier&#37;&#52;&#48;inria&#46;fr">Nicolas<span>&#46;</span>Rougier<span>&#64;</span>inria<span>&#46;</span>fr</a></p>
<ul class="last simple">
<li><p class="first"><a class="reference external" href="../index.html">Home</a></p>
</li>
<li><p class="first"><a class="reference external" href="../research/index.html">Research</a></p>
</li>
<li><p class="first"><a class="reference external" href="../teaching/index.html">Teaching</a></p>
<ul>
<li><p class="first"><a class="reference internal" href="#scientific-visualization">Scientific Visualization</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#numerical-computing">Numerical computing</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#c-crash-course">C++ Crash Course</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#reinforcement-learning">Reinforcement Learning</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#neural-networks">Neural Networks</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#computer-security">Computer Security</a></p>
</li>
<li><p class="first"><a class="reference internal" href="#visual-attention">Visual attention</a></p>
</li>
</ul>
</li>
<li><p class="first"><a class="reference external" href="../coding/index.html">Coding</a></p>
</li>
<li><p class="first"><a class="reference external" href="../artwork/index.html">Artwork</a></p>
</li>
<li><p class="first"><a class="reference external" href="../news/index.html">News</a></p>
</li>
<li><p class="first"><a class="reference external" href="../blog/index.html">Blog</a></p>
</li>
</ul>
</div>
<div class="offset1 span7">
<div class="section" id="id1">
<h1>Teaching</h1>
<p>Here is a set of courses on various topics (scientific visualization, neural
networks, computer security and visual attention). Some have been taught at the
national level and consequently they're in French, some others have been taught
at the international level and they're in English. Sources for the slides are
available upon request (by mail).</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="section" id="scientific-visualization">
<h2>Scientific Visualization</h2>
<div class="section" id="introduction">
<h3>Introduction</h3>
<img alt="../images/ScientificVisualization.png" class="img-left img-round" src="../images/ScientificVisualization.png" style="height: 140px;" />
<p>This lecture was given at Euroscipy 2012, Prace Winter School 2013 and
Euroscipy 2013. It introduces some very basic concepts on scientific
visualization, some good practices and presents a set of open source tools that
may be useful for your own research. This introduction does not require any
pre-requisites. This introduction is generally followed by the matplotlib
tutorial that you will find below.</p>
<p><a class="reference external" href="../downloads/ScientificVisualization.pdf">→ ScientificVisualization.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="matplotlib-tutorial">
<h3>Matplotlib tutorial</h3>
<img alt="matplotlib/figures/scatter.png" class="img-left img-round" src="matplotlib/figures/scatter.png" style="height: 140px;" />
<p>Matplotlib is probably the single most used Python package for 2D-graphics. It
provides both a very quick way to visualize data from Python and to output
publication-quality figures in many formats. This tutorial proposes to cover
the main aspects of matplotlib through a serie of exerices. This tutorial is
loosely based on the previous <a class="reference external" href="http://scipy-lectures.github.com/intro/matplotlib/matplotlib.html">tutorial</a> from the
<a class="reference external" href="http://scipy-lectures.github.com">scipy lecture notes</a>. It has now be
replaced by this one.</p>
<p><a class="reference external" href="matplotlib/matplotlib.html">→ Matplotlib tutorial</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="numerical-computing">
<h2>Numerical computing</h2>
<div class="section" id="numpy-beginner-tutorial">
<h3>Numpy beginner tutorial</h3>
<a class="reference external image-reference" href="numpy/numpy.html"><img alt="../images/numpy.png" class="img-round img-left" src="../images/numpy.png" style="height: 140px;" /></a>
<p>NumPy is the fundamental package for scientific computing with Python.
Besides its obvious scientific uses, NumPy can also be used as an efficient
multi-dimensional container of generic data. Arbitrary data-types can be
defined and this allows NumPy to seamlessly and speedily integrate with a wide
variety of projects.</p>
<p><a class="reference external" href="numpy/numpy.html">→ Numpy tutorial</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="numpy-exercises">
<h3>Numpy exercises</h3>
<img alt="../images/numpy-100.png" class="img-left img-round" src="../images/numpy-100.png" style="height: 140px;" />
<p>Here is a compilation of numpy exercises ranging from neophyte to very advanced
that have been collected from different sources (scipy lecture notes, stack
overflow, numpy user mailing list). The collection is not yet completed but
there are already a decent number of exercices to play with.</p>
<p><a class="reference external" href="numpy.100/index.html">→ 100 Numpy exercises</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="c-crash-course">
<h2>C++ crash course</h2>
<p>This is an introduction to C++ for C programmers. If you can't understand the
code below, you'd better start with a C tutorial:</p>
<pre class="literal-block">
#include &lt;stdio.h&gt;
void main (int argc, char **argv)
{
    printf( &quot;Hello World!\n&quot; );
}
</pre>
<p>Else, you can follow this <a class="reference external" href="c++-crash-course/index.html">link</a></p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="reinforcement-learning">
<h2>Reinforcement Learning</h2>
<p>This serie of lectures on reinforcement learning was given at the <a class="reference external" href="http://laconeu.cl">Third Latin
American Summer School in Computational Neuroscience</a>,
Valparaiso (Chile) in January 2014.</p>
<div class="section" id="part-i-introduction-definitions">
<h3>Part I - Introduction &amp; Definitions</h3>
<img alt="../images/ReinforcementLearning-1.png" class="img-left img-round" src="../images/ReinforcementLearning-1.png" style="height: 140px;" />
<p>This is an introduction to Markov decision processes (MDP).</p>
<p><a class="reference external" href="../downloads/ReinforcementLearning-1.pdf">→ ReinforcementLearning-1.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="part-ii-resolution-methods">
<h3>Part II - Resolution methods</h3>
<img alt="../images/ReinforcementLearning-2.png" class="img-left img-round" src="../images/ReinforcementLearning-2.png" style="height: 140px;" />
<p>This is an introduction to Reinforcement Learning (RL).</p>
<p><a class="reference external" href="../downloads/ReinforcementLearning-2.pdf">→ ReinforcementLearning-2.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="neural-networks">
<h2>Neural Networks</h2>
<div class="section" id="id4">
<h3>Introduction</h3>
<img alt="../images/LearningAndMemory.png" class="img-left img-round" src="../images/LearningAndMemory.png" style="height: 140px;" />
<p>This is a gentle introduction to learning, memory and artificial neural
networks for master students (in French).</p>
<p><a class="reference external" href="../downloads/LearningAndMemory.pdf">→ LearningAndMemory.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="perceptrons">
<h3>Perceptrons</h3>
<img alt="../images/Perceptron.png" class="img-left img-round" src="../images/Perceptron.png" style="height: 140px;" />
<p>Introduction to perceptron and multi-layer perceptron (in French).</p>
<p><a class="reference external" href="../downloads/Perceptron.pdf">→ Perceptron.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="self-organising-maps">
<h3>Self-Organising maps</h3>
<img alt="../images/Kohonen.png" class="img-left img-round" src="../images/Kohonen.png" style="height: 140px;" />
<p>Introduction to self-organising maps and Kohone maps (in French).</p>
<p><a class="reference external" href="../downloads/Kohonen.pdf">→ Kohonen.pdf</a></p>
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</div>
<div class="section" id="computer-security">
<h2>Computer Security</h2>
<img alt="../images/Security-Overview.png" class="img-left img-round" src="../images/Security-Overview.png" style="height: 140px;" />
<p>Depuis les heures glorieuses du &quot;phreaking&quot; où des adolescents cherchaient
simplement à téléphoner gratuitement (1960), jusqu'à la mise au point par des
états de virus informatiques pour des attaques ciblées (2010), le visage de la
cybercriminalité s'est radicalement transformé en l'espace de quelques
années. Là où l'on trouvait des passionés d'informatique, on trouve aujourd'hui
des états, des industries, des mafias et des &quot;script kiddies&quot;. Les possibilités
de piratage et de fraude se sont par ailleurs multipliées depuis la
généralisation de l'accès à internet et de la téléphonie mobile. Sachant que le
point d'entrée privilégié dans un système est l'utilisateur lambda, il est plus
que jamais nécessaire de rester vigilant.</p>
<div class="line-block">
<div class="line"><a class="reference external" href="../downloads/Security-Overview.pdf">→ Security-Overview.pdf</a></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="visual-attention">
<h2>Visual attention</h2>
<p>This serie of lectures on visual attention was given at the <a class="reference external" href="http://www.nii.ac.jp/en/">NII</a>, Tokyo (Japan) in December 2010.</p>
<div class="section" id="lecture-1-embodied-cognition">
<h3>Lecture 1 : Embodied Cognition</h3>
<img alt="../images/Tokyo-2010-Lecture-1.png" class="img-left img-round" src="../images/Tokyo-2010-Lecture-1.png" style="height: 140px;" />
<p>Twenty years ago, R. Brooks revealed to the A.I. community that elephants don't
play chess. Ten years later, A. Clark explained that <em>we ignore the fact that
the biological mind is, first and foremost, an organ for controlling the
biological body. Minds make motions, and they must make them fast - before the
predator catches you, or before your prey gets away from you.  Minds are not
disembodied logical reasoning devices.</em> This lecture proposes to look back at
(almost) 60 years of Artificial Intelligence researches in order to address the
question of what has been accomplished so far towards our understanding of
intelligence and cognition. In this context, we'll introduce the
action-perception loop, the embodied cognition paradigm and the symbol
grounding problem as it has been identified by Steve Harnad. This problem has
became prominent in the cognitive science society and the idea that a symbol is
much more than a mere meaningless token that can be processed through some
algorithm sheds a new light on higher brain functions. More specifically, we'll
explain how those theories can impact modeling on computer vision.</p>
<div class="line-block">
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-1.pdf">→ Lecture-1.pdf</a></div>
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-1-white.pdf">→ Lecture-1.pdf (printer friendly)</a></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="lecture-2-visual-attention">
<h3>Lecture 2: Visual Attention</h3>
<img alt="../images/Tokyo-2010-Lecture-2.png" class="img-left img-round" src="../images/Tokyo-2010-Lecture-2.png" style="height: 140px;" />
<p>This lecture proposes to review current psychological and physiological data as
and classical experiments related to visual attention as well as anatomical and
physiological data related to the oculomotor control in the primate. We will
introduce the two main forms of visual attention, namely exogeneous (bottom up)
and endogeneous (top down) visual attention that are known to play a critical
role in the perception and processing of a visual scene.  Facilitating and
inhibitory effects of visual attention will be presented in light of Posner
experiments (1980) related to the concept of inhibition of return that play a
major role in a number of computational models of visual attention. Finally,
integrative theories related to visual attention will be introduced, namely the
premotor theory of attention, the active perception paradigm and the deictic
codes for the embodiment of cognition.</p>
<div class="line-block">
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-2.pdf">→ Lecture-2.pdf</a></div>
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-2-white.pdf">→ Lecture-2.pdf (printer friendly)</a></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="lecture-3-dynamic-neural-fields">
<h3>Lecture 3: Dynamic Neural Fields</h3>
<img alt="../images/Tokyo-2010-Lecture-3.png" class="img-left img-round" src="../images/Tokyo-2010-Lecture-3.png" style="height: 140px;" />
<p>This lecture introduces main concepts related to classical artificial neural
networks as well as computational neuroscience.  Standard artificial neural
network models related to supervised, unsupervised and reinforcment learning
will be briefly introduced as well as key concepts from neuro-anatomy and
neuro-physiology.  This lecture will also focus on the dynamic neural field
(DNF) Theory as it has been originally introduced by Wilson and Cowan in the
early seventies and later formalized by S.I.  Amari and J.G. Taylor.  These
theories explain the dynamic of pattern formation for lateral-inhibition type
homogeneous neural fields with general connections. They show that, in some
conditions, continuous attractor neural networks are able to maintain a
localised bubble of activity in direct relation with the excitation provided by
a stimulation.  We will investigate further these theories in order to explain
how their functional properties can be linked to visual attention defined as
the capacity to attend to one stimulus in spite of noise, distractors or
saliency effects.</p>
<div class="line-block">
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-3.pdf">→ Lecture-3.pdf</a></div>
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-3-white.pdf">→ Lecture-3.pdf (printer friendly)</a></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="lecture-4-models-of-visual-attention">
<h3>Lecture 4: Models of Visual Attention</h3>
<img alt="../images/Tokyo-2010-Lecture-4.png" class="img-left img-round" src="../images/Tokyo-2010-Lecture-4.png" style="height: 140px;" />
<p>The visual exploration of a scene involves the interplay of several competing
processes (for example to select the next saccade or to keep fixation) and the
integration of bottom-up (e.g. contrast) and top-down information (the target
of a visual search task). Identifying the neural mechanisms involved in these
processes and the integration of these information remain a challenging
question. Visual attention refers to all these processes, both when the eyes
remain fixed (covert attention) and when they are moving (overt attention).
Popular computation models of visual attention consider that the visual
information remains fixed when attention is deployed while the primate are
executing around three saccadic eye movements per second, abruplty changing the
whole visual information.  We'll introduce in this lecture a model relying on
dynamic neural fields and show that covert and overt attention can emerge from
such a substratum.  We'll identify and propose a possible interaction of four
elementary mechanisms for selecting the next locus of attention, memorizing the
previously attended locations, anticipating the consequences of eye movements
and integrating bottom-up and top-down information in order to perform a visual
search task with saccadic eye movements.</p>
<div class="line-block">
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-4.pdf">→ Lecture-4.pdf</a></div>
<div class="line"><a class="reference external" href="../downloads/Tokyo-2010-Lecture-4-white.pdf">→ Lecture-4.pdf (printer friendly)</a></div>
<div class="line"><br /></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="footer">
<hr class="footer" />
<p>footer</p>

</div>
</body>
</html>
